# -*- coding: utf-8 -*-
"""Tugas Pekan 3 - NLP - TF IDF PPMI.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1QdE9llxNfItAGQQtTXoWvT8Fn3pINoH_

## **Semantik Vektor I : TF-IDF & PPMI**

Topik : Cyber Crime Whatsapp & Pendidikan Jarak Jauh


---


Clarisa Hasya Y - 1301174256
"""

import nltk
import numpy as np
import random
import string
import re
import math
from glob import glob
import heapq
import nltk
nltk.download('punkt')

#Read file txt
data = []
list_of_files = glob('a*.txt')   
for file_name in list_of_files:
  f = open(file_name, 'r', encoding='utf-8')
  data.append(f.read())
  f.close()
# data

"""**Tokenisasi**"""

corpus = []
for doc in data :
  corpus += nltk.sent_tokenize(doc)

for i in range(len(corpus)):
    corpus [i] = corpus[i].lower()
    corpus [i] = re.sub(r'\W',' ',corpus [i]) # hapus punctuation / tanda baca
    corpus [i] = re.sub(r'\s+',' ',corpus [i]) # hapus spasi berlebih

wordfreq = {}
for sentence in corpus:
    tokens = nltk.word_tokenize(sentence)
    for token in tokens:
        if token not in wordfreq.keys():
            wordfreq[token] = 1
        else:
            wordfreq[token] += 1

most_freq = heapq.nlargest(2000, wordfreq, key=wordfreq.get) # setting wordfreq bisa diubah sesuai dengan karakteristik data yang digunakan. Di sini akan digunakan frekuensi maksimum 2000.

# print(corpus)
# print(wordfreq)
# print(most_freq)

"""# **TF-IDF**

Sebuah dokumen adalah **1 Kalimat**

**IDF**
"""

word_idf_values = {}
for token in most_freq:
    doc_containing_word = 0
    for document in corpus:
        if token in nltk.word_tokenize(document):
            doc_containing_word += 1
    word_idf_values[token] = np.log10(len(corpus)/(doc_containing_word))

# print(word_idf_values)

"""**TF**"""

word_tf_values = {}
for token in most_freq:
    sent_tf_vector = []
    for document in corpus:
        doc_freq = 0
        for word in nltk.word_tokenize(document):
            if token == word:
                  doc_freq += 1
        # word_tf = doc_freq # tanpa normalisasi
        word_tf = doc_freq/len(nltk.word_tokenize(document)) # normalisasi dengan panjang dokumen
        sent_tf_vector.append(word_tf)
    word_tf_values[token] = sent_tf_vector

# print(word_tf_values)

"""**TF-IDF**"""

tfidf_values = []
for token in word_tf_values.keys():
    tfidf_sentences = [] # 1 dokumen adalah 1 kalimat
    for tf_sentence in word_tf_values[token]:
        tf_idf_score = tf_sentence * word_idf_values[token]
        tfidf_sentences.append(tf_idf_score)
    tfidf_values.append(tfidf_sentences)

# tfidf_values

tf_idf_modell = np.asarray(tfidf_values) # jumlah kata x jumlah kalimat
tf_idf_model = np.transpose(tf_idf_modell) # jumlah kalimat x jumlah kata
# print(tf_idf_model)
# print(tf_idf_modell)

"""**Ukuran Matriks TF-IDF**"""

# Ukuran matriks TF-IDF
print('Ukuran Matriks TF-IDF (jum kata x jum kalimat) : ', tf_idf_modell.shape) # jumlah kata x jumlah kalimat, dipakai untuk cosine similarity antar kata
print('Ukuran Matriks TF-IDF (jum kalimat x jum kata) : ', tf_idf_model.shape) # jumlah kalimat x jumlah kata, dipakai untuk cosine similarity antar kalimat

"""**Persentase TF-IDF yang tidak bernilai 0**"""

# type(tf_idf_model)
count = 0
count_all = tf_idf_model.shape[0]*tf_idf_model.shape[1]
for files in tf_idf_model:
  for data in files :
    if data != 0:
      count += 1

persen = (count/count_all)*100
print('Persentase TF-IDF yang tidak bernilai 0 : ', round(persen,2), '%')

"""**Cosine Similarity**

Antar Kalimat Topik yang Sama
"""

cos_sim_01 = np.dot(tf_idf_model[0],tf_idf_model[1])/np.linalg.norm(tf_idf_model[0])*np.linalg.norm(tf_idf_model[1])
print('Cosine Similarity Antar Kalimat Topik yang Sama (TF-IDF) : ', str(cos_sim_01))

cos_sim_02 = np.dot(tf_idf_model[300],tf_idf_model[280])/np.linalg.norm(tf_idf_model[300])*np.linalg.norm(tf_idf_model[280])
print('Cosine Similarity Antar Kalimat Topik yang Sama (TF-IDF) : ', str(cos_sim_02))

"""Antar Kalimat Topik yang Berbeda"""

cos_sim_03 = np.dot(tf_idf_model[5],tf_idf_model[140])/np.linalg.norm(tf_idf_model[5])*np.linalg.norm(tf_idf_model[140])
print('Cosine Similarity Antar Kalimat Topik yang Berbeda (TF-IDF) : ', str(cos_sim_03))

cos_sim_04 = np.dot(tf_idf_model[200],tf_idf_model[300])/np.linalg.norm(tf_idf_model[200])*np.linalg.norm(tf_idf_model[300])
print('Cosine Similarity Antar Kalimat Topik yang Berbeda (TF-IDF) : ', str(cos_sim_04))

"""Antar Kata Topik yang Sama"""

cos_simm_01 = np.dot(tf_idf_modell[0],tf_idf_modell[3])/np.linalg.norm(tf_idf_modell[0])*np.linalg.norm(tf_idf_modell[3]) # 'yang' & 'whatsapp'
print('Cosine Similarity Antar Kata (yang & whatsapp) Topik yang Sama (TF-IDF) : ', str(cos_simm_01))

cos_simm_02 = np.dot(tf_idf_modell[3],tf_idf_modell[17])/np.linalg.norm(tf_idf_modell[3])*np.linalg.norm(tf_idf_modell[17]) # 'whatsapp' & 'menjadi'
print('Cosine Similarity Antar Kata (whatsapp & menjadi) Topik yang Sama (TF-IDF) : ', str(cos_simm_02))

"""Antar Kata Topik yang Berbeda"""

cos_simm_03 = np.dot(tf_idf_modell[3],tf_idf_modell[12])/np.linalg.norm(tf_idf_modell[3])*np.linalg.norm(tf_idf_modell[12]) # 'whatsapp' & 'pembelajaran'
print('Cosine Similarity Antar Kata (whatsapp & pembelajaran) Topik yang Berbeda (TF-IDF) : ', str(cos_simm_03))

cos_simm_04 = np.dot(tf_idf_modell[12],tf_idf_modell[22])/np.linalg.norm(tf_idf_modell[12])*np.linalg.norm(tf_idf_modell[22]) # 'pembelajaran' & 'keamanan'
print('Cosine Similarity Antar Kata (pembelajaran & keamanan) Topik yang Berbeda (TF-IDF) : ', str(cos_simm_04))

"""# **PPMI**

**Matriks co-occurence (term, context)**
"""

# inisialisasi matriks co-occurrence
co_occurrence_mat = {}
for token_1 in wordfreq.keys():
  co_occurrence_terms = []
  for token_2 in wordfreq.keys():
     co_occurrence_mat[(token_1,token_2)] = 0

# set ukuran window
window_size = 2 # contoh, ukuran window = 2

# inisialisasi jumlah bigram (term, context) yang muncul
sum_term_context = 0 # jumlah kemunculan term, context

# proses
for sentence in corpus:
  tokens = nltk.word_tokenize(sentence)
  for i in range(0,len(tokens)):
    # konteks kata-kata sebelah kiri
    left_index = i-1
    while left_index >= 0 and left_index >= i-window_size:
      token_1 = tokens[i]
      token_2 = tokens[left_index]
      co_occurrence_mat[(token_1,token_2)] += 1
      sum_term_context += 1
      left_index = left_index - 1
    # konteks kata-kata sebelah kanan
    right_index = i+1
    while right_index < len(tokens) and right_index <= i+window_size:
      token_1 = tokens[i]
      token_2 = tokens[right_index] 
      co_occurrence_mat[(token_1,token_2)] += 1    
      sum_term_context += 1
      right_index = right_index + 1

bigram_count = {} # Inisialisasi jumlah kemunculan sebuah term sebagai bagian dari bigram

def print_cooccurrence_mat():
  str_token = '\t'
  for token in wordfreq.keys():
    str_token += '\t\t'+token
  # print(str_token)
  for token_1 in wordfreq.keys():
    str_row = token_1+'\t'
    curr_bigram_count = 0
    bigram_count[token_1] = 0
    #print(token_1)
    for token_2 in wordfreq.keys():
      str_row += '\t\t'+str(co_occurrence_mat[(token_1,token_2)])
      curr_bigram_count += co_occurrence_mat[(token_1,token_2)] # update jumlah kemunculan term
    bigram_count[token_1] = curr_bigram_count # assignemnt jumlah kemunculan term sebagai bagian dari bigram
    # print(str_row)

print_cooccurrence_mat()

# print(bigram_count)
# print(sum_term_context) # jumlah term/context yang muncul pada dokumen

"""**Ukuran Matriks co-occurence term-context**"""

# Ukuran Matriks co-occurence term-context
print('Ukuran Matriks co-occurence term-context : [', len(wordfreq), ',', len(wordfreq),']')

"""**Cosine Similarity (term, context)**"""

def cos_sim_term_con(aa,bb):  
  a , b , ab = 0, 0, 0
  for token in wordfreq.keys():
    ab += (co_occurrence_mat[(aa, token)] * co_occurrence_mat[(bb, token)])
    a += pow(co_occurrence_mat[(aa, token)], 2)
    b += pow(co_occurrence_mat[(bb, token)], 2)
  return (ab / (math.sqrt(a) * math.sqrt(b)))

cos_simmm_01 = cos_sim_term_con('yang', 'whatsapp')
cos_simmm_02 = cos_sim_term_con('whatsapp','menjadi')
cos_simmm_03 = cos_sim_term_con('whatsapp','pembelajaran')
cos_simmm_04 = cos_sim_term_con('pembelajaran','keamanan')

print('Cosine Similarity Antar Kata (yang & whatsapp) Topik yang Sama (co-occurrence term-context) : ', str(cos_simmm_01))
print('Cosine Similarity Antar Kata (whatsapp & menjadi) Topik yang Sama (co-occurrence term-context) : ', str(cos_simmm_02))
print('Cosine Similarity Antar Kata (whatsapp & pembelajaran) Topik yang Berbeda (co-occurrence term-context) : ', str(cos_simmm_03))
print('Cosine Similarity Antar Kata (pembelajaran & keamanan) Topik yang Berbeda (co-occurrence term-context) : ', str(cos_simmm_04))

"""**Matriks Probability (term, context)**"""

# definisikan dan isi matriks probability (term, context)
term_context_prob = {}
for token_1 in wordfreq.keys():
  for token_2 in wordfreq.keys():    
    term_context_prob[(token_1,token_2)] = co_occurrence_mat[(token_1,token_2)]/sum_term_context

def print_term_context_prob():
  str_token = '\t'
  for token in wordfreq.keys():
    str_token += '\t\t'+token
  print(str_token)
  for token_1 in wordfreq.keys():
    str_row = token_1+'\t'
    for token_2 in wordfreq.keys():
      str_row += '\t\t'+str(round(term_context_prob[(token_1,token_2)],4))
    print(str_row)

# print_term_context_prob()

"""**Matriks PPMI (term, context)**"""

ppmi_mat = {}

for token_1 in wordfreq.keys():
  for token_2 in wordfreq.keys(): 
    token_1_prob = bigram_count[token_1]/sum_term_context
    token_2_prob = bigram_count[token_2]/sum_term_context
    if term_context_prob[(token_1,token_2)] > 0:
      ppmi_mat[(token_1,token_2)] = max(round(math.log2(term_context_prob[(token_1,token_2)]/(token_1_prob*token_2_prob)), 4), 0)
    else: # kalau nilai probability = 0, tidak bisa dihitung log 2 -nya
      ppmi_mat[(token_1,token_2)] = None

def print_ppmi_mat():
  str_token = '\t'
  for token in wordfreq.keys():
    str_token += '\t\t'+token
  print(str_token)
  for token_1 in wordfreq.keys():
    str_row = token_1+'\t'
    #print(token_1)
    for token_2 in wordfreq.keys():
      str_row += '\t\t'+str(ppmi_mat[(token_1,token_2)])
    print(str_row)

# print_ppmi_mat()

"""**Ukuran Matriks PPMI**"""

# Ukuran Matriks PPMI
print('Ukuran Matriks PPMI : [', len(wordfreq), ',', len(wordfreq),']')

"""**Persentase PPMI yang tidak bernilai 0**"""

cnt = 0
cnt_all = len(ppmi_mat)

for token_1 in wordfreq.keys():
  for token_2 in wordfreq.keys(): 
    if (ppmi_mat[(token_1,token_2)] != None) and (ppmi_mat[(token_1,token_2)] != 0 ):
       cnt += 1
percent = (cnt/cnt_all) * 100
print('Persentase PPMI yang tidak bernilai 0 : ', round(percent,2), '%')

"""**PPMI antar kata**"""

def ppmi_antar_kata(token_1, token_2):
  token_1_prob = bigram_count[token_1]/sum_term_context
  token_2_prob = bigram_count[token_2]/sum_term_context
  if term_context_prob[(token_1,token_2)] > 0:
    ppmi = max(round(math.log2(term_context_prob[(token_1,token_2)]/(token_1_prob*token_2_prob)), 4), 0)
  else: # kalau nilai probability = 0, tidak bisa dihitung log 2 -nya
    ppmi = None
  return ppmi

ppmi_01 = ppmi_antar_kata('yang', 'whatsapp')
ppmi_02 = ppmi_antar_kata('whatsapp','menjadi')
ppmi_03 = ppmi_antar_kata('whatsapp','pembelajaran')
ppmi_04 = ppmi_antar_kata('pembelajaran','keamanan')

print('PPMI antar kata (yang & whatsapp) : ', str(ppmi_01))
print('PPMI antar kata (whatsapp & menjadi) : ', str(ppmi_02))
print('PPMI antar kata (whatsapp & pembelajaran) : ', str(ppmi_03))
print('PPMI antar kata (pembelajaran & keamanan) : ', str(ppmi_04))